<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Multi-Modal Masked Autoencoders for Learning Image-Spectrum Associations for Galaxy Evolution and Cosmology">
  <title>MMAE NeurIPS 2025</title>
  <link href="./mmae_neurips2025_files/bootstrap.min.css" rel="stylesheet">

  <!-- Additional Stylesheets -->
  <link href="./mmae_neurips2025_files/bootstrap-icons.css" rel="stylesheet">
  <link href="./mmae_neurips2025_files/boxicons.min.css" rel="stylesheet">
  <link href="./mmae_neurips2025_files/style.css" rel="stylesheet">

  <style>
    /* Base Typography */
    body {
      padding-top: 100px;
      font-family: Arial, sans-serif;
      font-size: 1.1rem;
      line-height: 1.6;
      color: #212529;
    }

    /* Navbar Styles */
    #header .container {
      flex-wrap: wrap;
    }

    #header .logo h3 {
      margin: 0;
      white-space: normal;
      word-wrap: break-word;
      overflow-wrap: break-word;
    }

    #header .logo h3 a {
      color: white !important;
      text-decoration: none;
      font-size: 1.5rem;
      white-space: normal;
      word-wrap: break-word;
      overflow-wrap: break-word;
    }

    #header {
      transition: all 0.3s ease;
      height: 100px;
      background: linear-gradient(rgb(97, 76, 165), rgb(171, 129, 255)), no-repeat center center;
    }

    /* Shrinking header */
    #header.shrink {
      height: 60px;
      background-color: rgba(0, 0, 0, 0.9);
    }

    #header.shrink .logo h3 a {
      font-size: 1.2rem;
    }

    #header.shrink .navbar {
      padding: 0;
    }

    .navbar ul li a {
      color: white !important;
      font-size: 1rem;
    }

    /* Smooth scrolling */
    html {
      scroll-behavior: smooth;
    }

    /* Banner Styles */
    .banner {
      background: linear-gradient(rgba(171, 129, 255, 0.8), rgba(255, 251, 220, 0.8)), no-repeat center center;
      background-size: cover;
      color: white;
      padding: 60px 0;
      position: relative;
      text-align: center;
    }

    .banner h1 {
      font-size: 2rem;
      font-weight: bold;
      margin-bottom: 20px;
    }

    .banner p {
      font-size: 1.1rem;
      margin-top: 0;
      max-width: 700px;
      margin-left: auto;
      margin-right: auto;
      line-height: 1.6;
    }

    /* Header Styles */
    h1, h2, h3 {
      font-weight: bold;
      line-height: 1.3;
    }

    h1 {
      font-size: 2rem;
      margin-bottom: 1rem;
    }

    h2 {
      font-size: 1.75rem;
      margin-bottom: 1rem;
    }

    h3 {
      font-size: 1.5rem;
      margin-bottom: 0.75rem;
    }

    p {
      font-size: 1.1rem;
      margin-bottom: 1rem;
    }

    /* Table Styles */
    table th {
      font-size: 1rem;
    }

    table td {
      font-size: 1rem;
    }

    /* Figure Caption Styles */
    .figure-caption {
      font-size: 0.95rem;
    }

    /* Footer Styles */
    footer p {
      font-size: 1rem;
      margin: 0;
    }

    #download-paper ul {
      list-style-type: disc;
      margin-left: 20px;
    }

    #download-paper li {
      list-style-type: disc;
    }

    /* Responsive Adjustments */
    @media (max-width: 768px) {
      .banner h1 {
        font-size: 1.75rem;
      }

      .banner p {
        font-size: 1rem;
      }

      h1 {
        font-size: 1.75rem;
      }

      h2 {
        font-size: 1.5rem;
      }

      h3 {
        font-size: 1.25rem;
      }

      p {
        font-size: 1rem;
      }

      table th, table td {
        font-size: 0.95rem;
      }

      .navbar ul li a {
        font-size: 0.95rem;
      }

      footer p {
        font-size: 0.95rem;
      }
    }

    /* Additional Spacing for Sections */
    #access {
      margin-bottom: 2rem;
    }

    #download-paper {
      margin-top: 2rem;
    }
  </style>

  <!-- Google tag (gtag.js)
  <script async="" src="./mmae_neurips2025_files/js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-7EGN5JER9N');
  </script>
<script async="" src="./mmae_neurips2025_files/js(1)"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-F1JF91QSWR');
</script></head>
<!-- Google tag (gtag.js)-->


<body>

<!-- ======= Header ======= -->
<header id="header" class="fixed-top d-flex align-items-center">
  <div class="container d-flex justify-content-between flex-wrap">

    <div class="logo">
      <h3><a href="https://datalab.astro.ucla.edu/index.html">UCLA Astrophysics Data Lab</a></h3>
    </div>

    <nav id="navbar" class="navbar">
      <ul>
        <li><a class="nav-link scrollto active" href="#overview">Overview</a></li>
        <li><a class="nav-link scrollto" href="#paper">Paper</a></li>
        <li><a class="nav-link scrollto" href="#dataset">Dataset</a></li>
        <li><a class="nav-link scrollto" href="#model-examples">Examples</a></li>
        <li><a class="nav-link scrollto" href="#code">Code</a></li>
        <li><a class="nav-link scrollto" href="#poster">Poster</a></li>
      </ul>
      <i class="bi bi-list mobile-nav-toggle"></i>
    </nav><!-- .navbar -->

  </div>
</header><!-- End Header -->

<div class="container my-5">

  <!-- ======= Banner Section ======= -->
  <section class="banner mb-5">
    <div class="container">
      <h1>Multi-Modal Masked Autoencoders for Learning Image-Spectrum Associations for Galaxy Evolution and Cosmology</h1>
      <p>
        This website consolidates the paper, poster, dataset, and code for our submission to NeurIPS 2025 <a href="https://ml4physicalsciences.github.io/2025/"><em>Machine Learning for the Physical Sciences</em></a> Workshop.
      </p>
    </div>
  </section>
  <!-- End Banner Section -->

  <!-- ======= Table of Contents ======= -->
  <section id="table-of-contents" class="mb-5">
    <h2>Table of Contents</h2>
    <ul class="list-group">
      <li class="list-group-item"><a href="#overview">Overview</a></li>
      <li class="list-group-item"><a href="#paper">Paper</a></li>
      <li class="list-group-item"><a href="#dataset">Dataset</a></li>
      <li class="list-group-item"><a href="#model-examples">Examples</a></li>
      <li class="list-group-item"><a href="#code">Code</a></li>
      <li class="list-group-item"><a href="#poster">Poster</a></li>
    </ul>
  </section>
  <!-- End Table of Contents -->

  <!-- ======= Overview Section ======= -->
  <section id="overview" class="mb-5">
    <h2>Overview</h2>
    <p>Upcoming surveys like <strong>LSST</strong> and <strong>Euclid</strong> will produce billions of galaxy images but comparatively few spectra, motivating models that learn cross-modal representations. We build <strong>GalaxiesML-Spectra</strong>, a dataset of 134,533 galaxy images (HSC-PDR2) and spectra (DESI-DR1) and adapt a <strong>Multi-Modal Masked Autoencoder (MMAE)</strong> to embed both images and spectra in a shared representation.</p>
    <p>The MMAE is a transformer-based architecture, which we train by masking 75% of the data and reconstructing missing image and spectral tokens. We use this model to test three applications: spectral and image reconstruction from heavily masked data and redshift regression from images alone. It recovers key physical features, such as galaxy shapes, atomic emission line peaks, and broad continuum slopes, though it struggles with fine image details and line strengths. For redshift regression, the MMAE performs comparably or better than prior multi-modal models in terms of prediction scatter even when missing spectra in testing. These results highlight both the potential and limitations of masked autoencoders in astrophysics and motivate extensions to additional modalities, such as text, for foundation models.</p>
  </section>
  <!-- End Overview Section -->

  <!-- Paper section -->
  <section id="paper" class="mb-5">
    <h2>NeurIPS ML4PS Conference Paper</h2>
    <p>Our paper submission to the NeurIPS 2025 <a href="https://ml4physicalsciences.github.io/2025/"><em>Machine Learning for the Physical Sciences</em></a> Workshop details the dataset construction, model architecture, and test results.</p>
    <a href="https://arxiv.org/pdf/2510.22527v1" class="btn btn-success btn-lg" download="">View Paper on arXiv (PDF)</a>
    <br><br>
  </section>

  <!-- Data Files Section -->
  <section id="dataset" class="mb-5">
    <h2>GalaxiesML-Spectra Dataset</h2>
    <p>We assembled a multi-modal dataset, referred to as <strong>GalaxiesML-Spectra</strong>, of 134,533 galaxies, each with 5-band images, 1D spectra, and spectroscopic redshifts. See the dataset access link for detailed information.</p>
    <p>GalaxiesML-Spectra is a crossmatched dataset between DESI and HSC data. The dataset is split into 127x127 pixel and 64x64 pixel image resolutions. When using the dataset, please cite:</p>
    <ul>
      <li><strong>DESI DR1</strong>: DESI Collaboration, <a href="https://arxiv.org/abs/2503.14745">Data Release 1 of the Dark Energy Spectroscopic Instrument</a> (2025)</li>
      <li><strong>HSC PDR2</strong>: Aihara, H., et al., <a href="https://academic.oup.com/pasj/article/71/6/114/5602617">Second Data Release of the Hyper Suprime-Cam Subaru Strategic Program</a>. Publications of the Astronomical Society of Japan, 71(6), 114 (2019).</li>
      <li><strong>GalaxiesML</strong>: Do, T., et al., <a href="https://ui.adsabs.harvard.edu/abs/2024arXiv241000271D">GalaxiesML: a dataset of galaxy images, photometry, redshifts, and structural parameters for machine learning</a>, (2024)</li>
    </ul>
    <div class="mb-3"></div>
    <a href="https://doi.org/10.5281/zenodo.16989593" class="btn btn-success btn-lg" target="_blank">Access Dataset</a>
  </section>

  <!-- Model Examples Section -->
  <section id="model-examples" class="mb-5">
    <h2>MMAE Example Applications</h2>
    <div class="text-center">
    <img src="./mmae_neurips2025_files/Architecture.png" alt="MMAE Architecture and Application to a Low-Redshift Source" class="img-fluid w-100 rounded">
    </div>
    <p><strong>Fig 1:</strong> The model's architecture and reconstruction process are shown for a low redshift source with 75% masking of both modalities. We measure the peak location, amplitude, and width of H-alpha in the augmented and generated spectra. The H-alpha line has an observed center at 7042.8 Å with a height of 3.04 and a width of 34.5 Å, while the model reconstructed it at 7066.8 Å with a height of 0.62 and a width of 528 Å.</p>

    <div class="text-center">
      <img src="./mmae_neurips2025_files/highredshiftsource.png" alt="Application to a High-Redshift Source" class="img-fluid w-75 rounded">
    </div>
    <p><strong>Fig 2:</strong> The model's reconstruction process is shown for a high redshift source with a fully masked spectrum and a fully unmasked image. We measure the peak location, amplitude, and width of Lyman-alpha and C IV in the augmented and generated spectra. The Lyman-alpha line has an observed center at 3851.6 Å with a height of 17.24 and a width of 48 Å, compared to a reconstructed center at 3923.6 Å, height 5.84, and width 312 Å. Similarly, the C IV line has an observed center at 4907.6 Å, height 7.07, and width 72 Å, while the reconstructed line is at 4931.6 Å, with height 2.48 and width 648 Å.</p>
    <div class="mb-3"></div>

    <div class="text-center">
      <img src="./mmae_neurips2025_files/photoz_vs_specz.png" alt="Redshift Regression Results" class="img-fluid w-75 rounded">
    </div>
    <p><strong>Fig 3:</strong> The model's redshift regression results for the entire redshift range are shown (right). The redshift predictions were obtained from test data that had 25% of the image masked and 100% of the spectrum masked. The low-redshift regime used for comparison to <a href="https://doi.org/10.1093/mnras/stae1450"> AstroCLIP</a> is shown in more detail in the bottom left. The top left panel shows the scatter of the MMAE compared to AstroCLIP and a <a href="https://iopscience.iop.org/article/10.3847/1538-4357/ad6d5a">BCNN model</a> for this low-redshift regime. Lower scatter corresponds to more precise predictions.</p>
  </section>

   <!-- Code Section -->
   <section id="code" class="mb-5">
    <h2>GitHub Repository</h2>
    <p>
      Python scripts for building and training the model, plotting notebooks, installation requirements, and model predictions are included in the repository.
     </p>
    <a href="https://github.com/astrodatalab/himes_2025/" class="btn btn-success btn-lg" target="_blank">Access Repository</a>
  </section>

  <!-- Poster Section -->
  <section id="poster" class="mb-5">
    <h2>Poster</h2>
    <p>This poster was presented at the NeurIPS 2025 <a href="https://ml4physicalsciences.github.io/2025/"><em>Machine Learning for the Physical Sciences</em></a> Workshop on December 6, 2025 in San Diego, California.</p>
    <div class="text-center">
      <img src="./mmae_neurips2025_files/HimesMorgan_NeurIPS2025_MMAEPoster.png" alt="NeurIPS 2025 ML4PS Poster" class="img-fluid w-75 rounded">
    </div>
    <a href="./mmae_neurips2025_files/HimesMorgan_NeurIPS2025_MMAEPoster.pdf" class="btn btn-success btn-lg" target="_blank">Download as PDF</a>
  </section>

<!-- License Section -->
  <section id="license" class="mb-5">
    <h2>License</h2>
    <p>This publication is licensed under a <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">Creative Commons Attribution 4.0 International License (CC BY 4.0)</a>.</p>
  </section>
</div>

<!-- ======= Footer ======= -->
<footer style="position: relative; bottom: 0; left: 0; width: 100%; background-color: rgb(0, 0, 0); color: rgb(255, 255, 255); text-align: center; padding: 8px 0; margin-top: 20px; font-size: 14px;">
  <p style="margin: 0; color: rgb(255, 255, 255) !important; opacity: 1 !important;">© 2025 UCLA Astrophysics Datalab. All rights reserved.</p>
</footer>

<script src="./mmae_neurips2025_files/jquery-3.5.1.slim.min.js"></script>
<script src="./mmae_neurips2025_files/bootstrap.bundle.min.js"></script>

<!-- Script to toggle the shrink class based on scroll position -->
<script>
  window.onscroll = function () {
    var header = document.getElementById("header");
    if (document.documentElement.scrollTop > 50) {
      header.classList.add("shrink");
    } else {
      header.classList.remove("shrink");
    }
  };
</script>

</body></html>